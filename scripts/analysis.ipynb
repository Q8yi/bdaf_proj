{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ae8d8-eb4e-4efa-824d-3bbcc03efc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49f15f-7f0e-4b55-af99-3d36927d41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_donal(df, user_name, cleaned=False):\n",
    "    '''\n",
    "    Current data have too many tweets posted by donald trump, pmarca, kaiynne\n",
    "    hence to balance the different class of user_name tweets,\n",
    "    we randomly choose approximately 100 tweets made by donald trump\n",
    "    (which is around 40% of current donaldtrump tweets)\n",
    "    '''\n",
    "    if (not cleaned):\n",
    "        print(\" JCSDNJNF\")\n",
    "        target_rows =  df[df['user_name'] == user_name]\n",
    "    else:\n",
    "        target_rows = df[df[f'{user_name}'] == 1]\n",
    "    n_to_drop = len(target_rows) - 100 # most of other user_name has around 100 rows\n",
    "\n",
    "    drop_indices = np.random.choice(target_rows.index, size=n_to_drop, replace=False)\n",
    "\n",
    "    df = df.drop(drop_indices)\n",
    "    print(len(df[df['user_name'] == user_name]) if not cleaned else len(df[df[f'{user_name}'] == 1]))\n",
    "    print(df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307b767-59df-49bc-883a-1f3879d84d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = { 'avg' : ['avg_fee', 'avg_value'], 'gas' : ['avg_gas_price_in_wei', 'avg_value_in_wei'], \\\n",
    "                    'prices' : ['Open','High','Low','Close','Volume','Market Cap'], 'transac' : ['avg_count']}\n",
    "\n",
    "def get_top10_corr(df, selected_columns, drop_columns):\n",
    "    corr = df.drop(columns=drop_columns).corr()\n",
    "\n",
    "    display(corr.style.background_gradient(cmap='coolwarm'))\n",
    "    corr_selected = corr[selected_columns].drop(index=selected_columns)  # remove self-correlations\n",
    "\n",
    "    corr_selected_abs = corr_selected.abs() #absolute ranking\n",
    "    total = []\n",
    "\n",
    "    for col in selected_columns:\n",
    "        top10 = corr_selected_abs[col].sort_values(ascending=False).head(10)\n",
    "        total.extend(top10.index.tolist())\n",
    "        plt.figure()\n",
    "        top10.plot(kind='bar')\n",
    "        plt.title(f'Top 10 Correlations with {col}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return total\n",
    "#get_top10_corr(merged_df, selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c81d87-f8a1-49f0-ab49-b247da0bc3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "tweet = pd.read_csv(\"../datasets/tweets/tweets_all2.csv\")\n",
    "\n",
    "tweet['date'] = pd.to_datetime(tweet['date'])\n",
    "tweet = tweet[tweet.date > datetime(2020,1,1)]\n",
    "tweet = balance_donal(tweet, 'realDonaldTrump')\n",
    "tweet = balance_donal(tweet, 'pmarca')\n",
    "tweet = balance_donal(tweet, 'kaiynne')\n",
    "\n",
    "\n",
    "#tweet.user_name.value_counts().values #.plot(type='bar')\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(x=tweet.user_name.value_counts().index, y=tweet[tweet.date > datetime(2020,1,1)].user_name.value_counts().values)\n",
    "])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febfc2bd-a3fc-49ba-b243-cf7da66b9cac",
   "metadata": {},
   "source": [
    "# Analyse correlation between blockchain fees and whether particular user_name has made a tweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c4d384-1f84-44b7-a6b9-f5c30b0dff51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chains = ['bit', 'doge', 'eth', 'polygon', 'solana', 'optimisim', 'tron', 'fanthom', 'cronos', 'avalanche', 'arbitrum']\n",
    "types = ['gas', 'transac', 'avg']\n",
    "\n",
    "dfs = []\n",
    "df_names = []\n",
    "\n",
    "directory = '../datasets/network/network_data'\n",
    "\n",
    "tweet = pd.read_csv(\"../datasets/tweets/cleaned_tweets2.csv\")\n",
    "tweet.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "tweet['date'] = pd.to_datetime(tweet['date'].map(lambda x : x[:10]))\n",
    "tweet = tweet[tweet['date'] > datetime(2020, 1, 1)]\n",
    "tweet = balance_donal(tweet, 'user_name_realDonaldTrump', True)\n",
    "tweet = balance_donal(tweet, 'user_name_pmarca', True)\n",
    "tweet = balance_donal(tweet, 'user_name_kaiynne', True)\n",
    "#tweet\n",
    "\n",
    "top_influecers = {}\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        print(filename)\n",
    "        df = pd.read_csv(file_path, index_col=False)\n",
    "        df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        dfs.append(df)\n",
    "        df_names.append(filename[:-4])\n",
    "        merged_df = pd.merge(df, tweet, on=['date'], how='left')\n",
    "        merged_df.fillna(0, inplace=True) # there are days when there is no tweets so will be filled as -1\n",
    "        #merged_df.to_csv(f\"{filename}_and_tweets.csv\")\n",
    "        corr = merged_df.drop(columns=['date']).corr()\n",
    "        data_type = filename[:-4].split(\"_\")[1]\n",
    "        total = get_top10_corr(merged_df, selected_columns[data_type], ['date'])\n",
    "        for user in total:\n",
    "            if user not in top_influecers.keys():\n",
    "                top_influecers[user] = 1\n",
    "            else:\n",
    "                top_influecers[user] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5021edf2-1b4a-46c4-9f35-c416b5ad36d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75669b12-6249-440f-8b45-7a736528f9b4",
   "metadata": {},
   "source": [
    "# Analyse correlation between prices and whether particular user_name has made a tweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aed1c11-6d64-46e8-bf29-09a6e58b75bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chains = ['bit', 'doge', 'eth', 'polygon', 'solana', 'optimisim', 'tron', 'fanthom', 'cronos', 'avalanche', 'arbitrum']\n",
    "types = ['gas', 'transac', 'avg']\n",
    "\n",
    "dfs = []\n",
    "df_names = []\n",
    "\n",
    "directory = '../datasets/network/prices'\n",
    "'''\n",
    "tweet = pd.read_csv(\"../datasets/tweets/cleaned_tweets2.csv\")\n",
    "tweet.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "tweet['date'] = pd.to_datetime(tweet['date'].map(lambda x : x[:10]))\n",
    "tweet = tweet[tweet['date'] > datetime(2020, 1, 1)]\n",
    "tweet = balance_donal(tweet, 'realDonaldTrump')\n",
    "tweet = balance_donal(tweet, 'pmarca')\n",
    "tweet = balance_donal(tweet, 'kaiynne')\n",
    "'''\n",
    "\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        print(filename)\n",
    "        df = pd.read_csv(file_path, index_col=False)\n",
    "        #df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "        df['date'] = pd.to_datetime(df['Start'])\n",
    "        dfs.append(df)\n",
    "        df_names.append(filename[:-4])\n",
    "        merged_df = pd.merge(df, tweet, on=['date'], how='left')\n",
    "        merged_df.fillna(0, inplace=True) # there are days when there is no tweets so will be filled as 0\n",
    "        #merged_df.to_csv(f\"{filename}_and_tweets.csv\")\n",
    "        data_type = filename[:-4].split(\"_\")[0]\n",
    "        total = get_top10_corr(merged_df, selected_columns['prices'], ['date', 'Start', 'End'])\n",
    "        for user in total:\n",
    "            if user not in top_influecers.keys():\n",
    "                top_influecers[user] = 1\n",
    "            else:\n",
    "                top_influecers[user] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba86ee5-273c-4102-9c55-6dc8f7a79a94",
   "metadata": {},
   "source": [
    "# get correlation in terms of one day changes in prices / blockchain fees in relation to tweets made by a user_name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae146b-2be3-4dac-974f-611b3df3fbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = '../datasets/network/merged'\n",
    "selected_columns = { 'avg' : ['avg_fee', 'avg_value'], 'gas' : ['avg_gas_price_in_wei', 'avg_value_in_wei'], \\\n",
    "                     'transac' : ['avg_count']}\n",
    "\n",
    "drop_columns = {'avg' : ['date'], 'gas' : ['date'], 'transac' : ['date']}\n",
    "\n",
    "\n",
    "# have 2 kind of file , csv and parquet\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "\n",
    "        print(filename)\n",
    "        #read the files\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df.sort_values(by='date', inplace=True)\n",
    "\n",
    "        #retrieve respective file columns\n",
    "        cols = selected_columns.get(filename.split('_')[1], ['Open','High','Low','Close','Volume'])\n",
    "        del_cols = drop_columns.get(filename.split('_')[1], ['Start','End','date', 'Market Cap'])\n",
    "        del_cols.append('Unnamed: 0')\n",
    "        sel = []\n",
    "        print(df)\n",
    "        for col in cols:\n",
    "            df[f'{col}_diff'] = df[f'{col}'].astype(float).diff()\n",
    "            df[f'{col}_direction'] = (df[f'{col}_diff'] > 0).astype(int) #if current is more than second return as 1 else 0\n",
    "            print(df.head(5))\n",
    "            del_cols.append(f'{col}_diff')\n",
    "            del_cols.append(f'{col}')\n",
    "            sel.append(f'{col}_direction')\n",
    "\n",
    "        df.drop(columns=del_cols, inplace=True)\n",
    "        corr = df.corr()\n",
    "        data_type = filename[:-4].split(\"_\")[1]\n",
    "        total = get_top10_corr(df, sel, [])\n",
    "\n",
    "        for user in total:\n",
    "            if user not in top_influecers.keys():\n",
    "                top_influecers[user] = 1\n",
    "            else:\n",
    "                top_influecers[user] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf0c3b-e8e1-4e9d-bd50-6f077e7060d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_influecers = {k: v for k, v in top_influecers.items() if 'user_name' in k}\n",
    "top10_influecers = dict(sorted(top_influecers.items(), key=lambda item: item[1], reverse=True)[:10])\n",
    "plt.bar(top10_influecers.keys(), top10_influecers.values())\n",
    "val = list(top10_influecers.values())\n",
    "user = list(top10_influecers.keys())\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "for i in range(10):\n",
    "    plt.text(user[i], val[i], val[i], ha='center')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
